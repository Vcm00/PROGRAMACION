{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 04. Clasificaci\u00f3n con MLP\n", "Soluciones a los ejercicios de clasificaci\u00f3n."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Este notebook implementa cuatro ejemplos de clasificaci\u00f3n usando PyTorch."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch.utils.data import TensorDataset, DataLoader\n", "from torcheval.metrics import BinaryAccuracy, BinaryConfusionMatrix, MulticlassConfusionMatrix\n", "from sklearn.datasets import make_blobs, make_circles, make_moons\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Funciones auxiliares"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, dataloader, loss_fn, optimizer, epochs=10):\n", "    for _ in range(epochs):\n", "        model.train()\n", "        for features, targets in dataloader:\n", "            out = model(features)\n", "            loss = loss_fn(out, targets)\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejercicio 1 - `make_blobs` con cuatro categor\u00edas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = make_blobs(centers=4, cluster_std=0.8)\n", "\n", "x_mean, x_std = X.mean(), X.std()\n", "X_norm = (X - x_mean) / x_std\n", "\n", "tensor_X = torch.tensor(X_norm, dtype=torch.float32)\n", "tensor_y = torch.tensor(y, dtype=torch.long)\n", "dataset = TensorDataset(tensor_X, tensor_y)\n", "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n", "\n", "class MLP(torch.nn.Module):\n", "    def __init__(self, num_features, num_classes):\n", "        super().__init__()\n", "        self.layers = torch.nn.Sequential(\n", "            torch.nn.Linear(num_features, 50),\n", "            torch.nn.ReLU(),\n", "            torch.nn.Linear(50, 25),\n", "            torch.nn.ReLU(),\n", "            torch.nn.Linear(25, num_classes)\n", "        )\n", "    def forward(self, x):\n", "        return self.layers(x)\n", "\n", "model = MLP(num_features=2, num_classes=4)\n", "criterion = torch.nn.CrossEntropyLoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n", "train_model(model, dataloader, criterion, optimizer, epochs=20)\n", "\n", "model.eval()\n", "preds = torch.argmax(model(tensor_X), dim=1)\n", "cm = MulticlassConfusionMatrix(num_classes=4)\n", "cm.update(preds, tensor_y)\n", "print(cm.compute())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejercicio 2 - `make_circles`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "# generate two circle datasets and shift one to create four classes\n", "X1, y1 = make_circles(noise=0.1, factor=0.2)\n", "X2, y2 = make_circles(noise=0.1, factor=0.2)\n", "X2 += np.array([3.0, 3.0])\n", "# adjust labels so classes become 0,1,2,3\n", "y2 += 2\n", "X = np.vstack([X1, X2])\n", "y = np.concatenate([y1, y2])\n", "\n", "X_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n", "tensor_X = torch.tensor(X_norm, dtype=torch.float32)\n", "tensor_y = torch.tensor(y, dtype=torch.long)\n", "\n", "dataset = TensorDataset(tensor_X, tensor_y)\n", "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n", "\n", "model = MLP(num_features=2, num_classes=4)\n", "criterion = torch.nn.CrossEntropyLoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n", "train_model(model, dataloader, criterion, optimizer, epochs=20)\n", "\n", "model.eval()\n", "preds = torch.argmax(model(tensor_X), dim=1)\n", "cm = MulticlassConfusionMatrix(num_classes=4)\n", "cm.update(preds, tensor_y)\n", "print(cm.compute())\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejercicio 3 - `make_moons`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = make_moons(noise=0.1)\n", "X_norm = (X - X.mean()) / X.std()\n", "tensor_X = torch.tensor(X_norm, dtype=torch.float32)\n", "tensor_y = torch.tensor(y, dtype=torch.float32)\n", "dataset = TensorDataset(tensor_X, tensor_y)\n", "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n", "\n", "model = BinaryMLP(num_features=2)\n", "criterion = torch.nn.BCEWithLogitsLoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n", "train_model(model, dataloader, criterion, optimizer, epochs=20)\n", "\n", "model.eval()\n", "out = model(tensor_X)\n", "preds = (out > 0).int()\n", "cm = BinaryConfusionMatrix()\n", "cm.update(preds, tensor_y.int())\n", "print(cm.compute())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejercicio 4 - Datos de infidelidad"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["url = 'https://raw.githubusercontent.com/mcstllns/UNIR2024/main/data-affairs.csv'\n", "data = pd.read_csv(url)\n", "X = data.drop('affairs', axis=1)\n", "y = data['affairs'].astype(float)\n", "\n", "X_norm = (X - X.mean()) / X.std()\n", "tensor_X = torch.tensor(X_norm.values, dtype=torch.float32)\n", "tensor_y = torch.tensor(y.values, dtype=torch.float32)\n", "dataset = TensorDataset(tensor_X, tensor_y)\n", "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n", "\n", "model = BinaryMLP(num_features=X.shape[1])\n", "criterion = torch.nn.BCEWithLogitsLoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n", "train_model(model, dataloader, criterion, optimizer, epochs=20)\n", "\n", "model.eval()\n", "out = model(tensor_X)\n", "preds = (out > 0).int()\n", "acc = BinaryAccuracy()\n", "acc.update(preds, tensor_y.int())\n", "print('accuracy:', acc.compute().item())"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 4}
